{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "af0a8a22",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 164\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to retrieve the category page: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcategory_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    163\u001b[0m \u001b[38;5;66;03m# # # Create a master DataFrame containing data from all categories\u001b[39;00m\n\u001b[1;32m--> 164\u001b[0m master_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([pd\u001b[38;5;241m.\u001b[39mDataFrame(data) \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m all_product_data], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    166\u001b[0m \u001b[38;5;66;03m# # # Save the master DataFrame to a CSV file\u001b[39;00m\n\u001b[0;32m    167\u001b[0m master_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDr_Batra_Products.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[46], line 164\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to retrieve the category page: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcategory_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    163\u001b[0m \u001b[38;5;66;03m# # # Create a master DataFrame containing data from all categories\u001b[39;00m\n\u001b[1;32m--> 164\u001b[0m master_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([pd\u001b[38;5;241m.\u001b[39mDataFrame(data) \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m all_product_data], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    166\u001b[0m \u001b[38;5;66;03m# # # Save the master DataFrame to a CSV file\u001b[39;00m\n\u001b[0;32m    167\u001b[0m master_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDr_Batra_Products.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:709\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    703\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    704\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    705\u001b[0m     )\n\u001b[0;32m    707\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    708\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 709\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, typ\u001b[38;5;241m=\u001b[39mmanager)\n\u001b[0;32m    710\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    711\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:481\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    478\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    479\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 481\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[38;5;241m=\u001b[39mdtype, typ\u001b[38;5;241m=\u001b[39mtyp, consolidate\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:115\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 115\u001b[0m         index \u001b[38;5;241m=\u001b[39m _extract_index(arrays)\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    117\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:655\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    653\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[0;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    657\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[0;32m    658\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    659\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    660\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Define the base URL of the website\n",
    "\n",
    "\n",
    "# List of category URLs to scrape\n",
    "base_url =\"https://products.drbatras.com/products/\"\n",
    "add_urls = [\n",
    "            \"dr-batra-s-age-defying-skin-firming-serum-50-g/\",\"dr-batra-s-normal-shampoo/\"\n",
    "            ]    \n",
    "\n",
    "# Create an empty list to store all product data\n",
    "all_product_data = []\n",
    "\n",
    "for url in add_urls:\n",
    "# Construct the full URL for the category\n",
    "\n",
    "    product_url = base_url+url\n",
    "    # Send an HTTP GET request to the category page\n",
    "    response = requests.get(product_url)\n",
    "    \n",
    "    # Check if the request was successful (status code 200)\n",
    "    if response.status_code == 200:\n",
    "        # Parse the HTML content of the category page using BeautifulSoup\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "        # Create lists to store product details for this category\n",
    "        product_names = []\n",
    "        product_prices = []\n",
    "        product_SKU = []\n",
    "        product_benef = []\n",
    "        product_ingred = []\n",
    "        product_detail = []\n",
    "        product_description = []\n",
    "        benefit =[]\n",
    "        benefit=\"\"\n",
    "        ingredient = \"\"\n",
    "        ab=\"\"\n",
    "        bc=\"\"\n",
    "        cd=\"\"\n",
    "        other =\"\"\n",
    "        htext =\"\"\n",
    "        ptext = \"\"\n",
    "        product_size = \"\"\n",
    "        prod_description =\"\"\n",
    "        prod_benefits = \"\"\n",
    "        prod_ingredients = \"\"\n",
    "        prod_details = \"\"\n",
    "#         product_sku = []\n",
    "        totalbf =\"\"\n",
    "        \n",
    "#         k=soup.find(\"h1\", class=\"ProductMeta__Title Heading u-h2\").text\n",
    "# # ----------------------------------------------   PRODUCT NAME  --------------------------------------\n",
    "        product_elements = soup.find_all('div', class_='ProductMeta')\n",
    "        \n",
    "        for product in product_elements:\n",
    "            product_name = product.find('h1', class_='ProductMeta__Title Heading u-h2').text.strip()\n",
    "#             print(product_name)\n",
    "            \n",
    "# # --------------------------------------------------------------------------------------------------------\n",
    "# # -------------------------------------     Product Price    ---------------------------------------------\n",
    "        product_price = soup.find_all('div',class_='ProductMeta__PriceList Heading')\n",
    "        \n",
    "        for product in product_price : \n",
    "            product_price = product.find('span',class_ = 'ProductMeta__Price Price Price--highlight Text--subdued u-h4').text.strip()\n",
    "#             print(product_price)\n",
    "# # ---------------------------------------------------------------------------------------------------------\n",
    "# # ----------------------------------------    SKU Size    -------------------------------------------------\n",
    "        product_sku = soup.find_all('ul', class_='SizeSwatchList HorizontalList HorizontalList--spacingTight')\n",
    "    \n",
    "        for product in product_sku :\n",
    "            lis=product.find_all('li',class_='HorizontalList__Item')\n",
    "            for li in lis:\n",
    "                product_size = li.find('label').text.strip()+ \", \" + product_size \n",
    "#             print(product_size)\n",
    "# # ----------------------------------------------------------------------------------------------------------\n",
    "# ------------------------------------------ Description ------------------------------------------------\n",
    "        product_description = soup.find_all('span',class_='easytabs-header-text ui-tabs-anchor js-no-transition')\n",
    "        \n",
    "        for product in product_description :\n",
    "            if product.text.strip() == \"Description\" :\n",
    "                des = product.find_next('div', class_='easytabs-content-holder')\n",
    "            description = des.find_all('p')\n",
    "        for descrip in description :\n",
    "            prod_description = descrip.text.strip() + \"\\n\" + prod_description\n",
    "#         print(prod_description)\n",
    "\n",
    "# -------------------------------------------------------------------------------------------------------------\n",
    "# -----------------------------------------    Benefits     ---------------------------------------------------\n",
    "        product_benefits = soup.find_all('span',class_='easytabs-header-text ui-tabs-anchor js-no-transition')\n",
    "        \n",
    "        for product in product_benefits :\n",
    "            if product.text.strip() == \"Benefits:-\" :\n",
    "                des = product.find_next('div', class_='easytabs-content-holder')\n",
    "            if product.text.strip() == \"Benefits\" :\n",
    "                des = product.find_next('div', class_='easytabs-content-holder')\n",
    "            benefits = des.find_all('li')\n",
    "        for benefit in benefits :\n",
    "            prod_benefits = benefit.text.strip() + \"\\n\" + prod_benefits\n",
    "#         print(prod_benefits)\n",
    "    \n",
    "# -------------------------------------------------------------------------------------------------------------\n",
    "# -----------------------------------------    Ingredients     ---------------------------------------------------\n",
    "        product_ingredients = soup.find_all('span',class_='easytabs-header-text ui-tabs-anchor js-no-transition')\n",
    "        \n",
    "        for product in product_ingredients :\n",
    "            if product.text.strip() == \"Key Ingredients:-\" :\n",
    "                ingred = product.find_next('div', class_='easytabs-content-holder')\n",
    "            elif product.text.strip() == \"Ingredients\" :\n",
    "                ingred = product.find_next('div', class_='easytabs-content-holder')\n",
    "                ingredients = ingred.find_all('li')\n",
    "            for ingredient in ingredients :\n",
    "                prod_ingredients = ingredient.text.strip() + \"\\n\" + prod_ingredients\n",
    "#         print(prod_ingredients)\n",
    "# ----------------------------------------------------------------------------------------------------------------\n",
    "# -----------------------------------------    Product Details     ----------------------------------------------- \n",
    "        product_details = soup.find_all('span',class_='easytabs-header-text ui-tabs-anchor js-no-transition')\n",
    "        \n",
    "        for product in product_details :\n",
    "            if product.text.strip() == \"Product Details:-\" :\n",
    "                dt = product.find_next('div', class_='easytabs-content-holder')\n",
    "            elif product.text.strip() == \"Other Details:-\" :\n",
    "                dt = product.find_next('div', class_='easytabs-content-holder')\n",
    "            details = dt.find_all('ul')\n",
    "            if details is not None: \n",
    "                for detail in details :\n",
    "                    prod_details = detail.text.strip() + detail.find('span').text.strip() + \"\\n\" + prod_details  \n",
    "#         print(prod_details)    \n",
    "\n",
    "# -----------------------------------------------------------------------------------------------------------------\n",
    "# -------------------------------------    Appending Queries    -----------------------------------------------------\n",
    "    \n",
    "# #     Adding the required data into a tabular format.\n",
    "    \n",
    "        product_names.append(product_name)\n",
    "        product_prices.append(product_price)\n",
    "        product_SKU.append(product_size)    \n",
    "        product_description.append(prod_description)\n",
    "        product_benef.append(prod_benefits)\n",
    "        product_ingred.append(prod_ingredients)\n",
    "        product_detail.append(prod_details)\n",
    "   \n",
    "    \n",
    "# #         # Create a DataFrame for this category's product data\n",
    "        category_product_data = {\n",
    "                                    'Product Name': product_names,\n",
    "                                    'Product Price': product_prices,\n",
    "                                    'Product SKU': product_SKU,\n",
    "                                    'Description': product_description,\n",
    "                                    'Product Benefits': product_benef,\n",
    "                                    'Product Ingredients': product_ingred,\n",
    "                                    'Product Details' : product_detail\n",
    "                                    }\n",
    "    \n",
    "# #         # Append the category data to the overall list\n",
    "        all_product_data.append(category_product_data)\n",
    "    \n",
    "    else:\n",
    "        print(f\"Failed to retrieve the category page: {category_url}\")\n",
    "    \n",
    "# # # Create a master DataFrame containing data from all categories\n",
    "master_df = pd.concat([pd.DataFrame(data) for data in all_product_data], ignore_index=True)\n",
    "    \n",
    "# # # Save the master DataFrame to a CSV file\n",
    "master_df.to_csv('Dr_Batra_Products.csv', index=False)\n",
    "print(\"All product details scraped and saved to 'all_product_details.csv'\")\n",
    "master_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5278fd04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
